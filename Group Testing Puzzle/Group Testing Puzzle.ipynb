{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0f32ae",
   "metadata": {},
   "source": [
    "# Group Testing Puzzle\n",
    "## Problem Statement\n",
    "Given a population of $N$ people who may or may not have COVID, what is the expected minimum number of COVID tests you'd need to administer to determine who does and doesn't have COVID? What would your testing algorithm be?\n",
    "### Assumptions\n",
    "- A COVID test is 100% accurate (i.e. no false-positives or false-negatives).\n",
    "- You can apply a single test to multiple people at a time, it will show positive if at least 1 person partaking in that test is positive.\n",
    "- The chance of a person having COVID is a constant $C$\n",
    "\n",
    "### Extensions\n",
    "- What if the tests are not 100% accurate?\n",
    "- What if the probability of having COVID isn't uniform over the population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d7d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893b8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "C = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0f2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = lambda state: C**sum(state)*(1-C)**(N-sum(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = sum([-P(state)*np.log2(P(state)) for state in itertools.product([0,1], repeat=N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea225ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "queue = [(P(state),state) for state in itertools.product([0,1], repeat=N)]\n",
    "heapq.heapify(queue)\n",
    "\n",
    "while len(queue) > 1:\n",
    "    freq1, tree1 = heapq.heappop(queue)\n",
    "    freq2, tree2 = heapq.heappop(queue)\n",
    "    new_node = (freq1+freq2, (tree1,tree2))\n",
    "    heapq.heappush(queue, new_node)\n",
    "print(queue[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df7450",
   "metadata": {},
   "source": [
    "#### State Space\n",
    "$$ X \\in \\mathbb{Z}_{2}^{N} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed866f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space = list(itertools.product([0,1], repeat=N))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec877af",
   "metadata": {},
   "source": [
    "#### Probability Space\n",
    "$$ P(X=x) = C^{|x|} (1-C)^{N-|x|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff8e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = {state:P(state) for state in state_space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state,p in P.items():\n",
    "    print(state,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503da36",
   "metadata": {},
   "source": [
    "#### Subset Test Probability\n",
    "$$ P(X \\in T) = \\sum_{t \\in T} P(X=t) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961129a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_subset = {\n",
    "    tested: sum([\n",
    "        p \n",
    "        for state,p in P.items() \n",
    "        if any(np.array(state)*np.array(tested))\n",
    "    ]) \n",
    "    for tested in state_space\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f2288",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tested,p in P_subset.items():\n",
    "    print(tested,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42823cb3",
   "metadata": {},
   "source": [
    "#### Conditional Entropy\n",
    "$$ H(X|Y) = - \\sum_{x,y} P(X=x,Y=y) \\log \\frac{P(X=x,Y=y)}{P(Y=y)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_conditional_H(P, subset):\n",
    "    p_subset = sum([p for state,p in P.items() if any(np.array(state)*np.array(subset))])\n",
    "    subset = np.array(subset)\n",
    "    H = 0.0\n",
    "    for subset_result in [0,1]:\n",
    "        for state,p in P.items():\n",
    "            state = np.array(state)\n",
    "            viable = subset_result*any(subset*state) + (1-subset_result)*(not any(subset*state))\n",
    "            if viable:\n",
    "                #print(subset_result, state)\n",
    "                H -= p*np.log2(p/(subset_result*p_subset + (1-subset_result)*(1-p_subset)))\n",
    "    return H    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_H = None\n",
    "for test_set in state_space:\n",
    "    H = subset_conditional_H(P, test_set)\n",
    "    if not min_H or H < min_H:\n",
    "        min_H = H\n",
    "        min_test_set = test_set\n",
    "print(min_test_set)\n",
    "print(min_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3912de",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_result = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a722bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean probability space\n",
    "state_space = [state for state in state_space if subset_result*any(np.array(min_test_set)*np.array(state)) + (1-subset_result)*(not any(np.array(min_test_set)*np.array(state)))]\n",
    "P_sum = sum([P[state] for state in state_space])\n",
    "P = {state:P[state]/P_sum for state in state_space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d36c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state,p in P.items():\n",
    "    print(state,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342bd75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sets_arr = np.array([[0,1]])\n",
    "results_arr = np.array([1])\n",
    "state_space_arr = np.array(state_space)\n",
    "#print(state_space_arr[:,:,np.newaxis].shape, test_sets.T[np.newaxis,:,:].shape)\n",
    "#print(state_space_arr[:,:,np.newaxis] * test_sets.T[np.newaxis,:,:])\n",
    "\n",
    "#print(state_space_arr)\n",
    "\n",
    "#np.any(np.array(state_space)*mask, axis=1)\n",
    "#~np.any(np.array(state_space)*mask, axis=1)\n",
    "\n",
    "test_results = np.any(state_space_arr[:,:,np.newaxis] * test_sets_arr.T[np.newaxis,:,:], axis=1)\n",
    "consistent_state = np.all(test_results == results_arr, axis=1)\n",
    "reduced_state_space = state_space_arr[consistent_state]\n",
    "#true_states = np.all(, axis=1)\n",
    "#print(results_arr)\n",
    "#print(test_results)\n",
    "print(consistent_state)\n",
    "\n",
    "reduced_state_space = state_space_arr[consistent_state]\n",
    "known_values = np.logical_or(reduced_state_space.all(axis=0), np.logical_not(reduced_state_space).all(axis=0))\n",
    "#np.any(np.array([1,1,0,0])*known_values)\n",
    "test_set_arr = np.array([1,0,0,1])\n",
    "covered_tests = np.logical_not(np.any(test_sets_arr * np.logical_not(test_set_arr), axis=1))\n",
    "covered_tests = test_sets_arr[covered_tests]\n",
    "covering = np.any(covered_tests, axis=0)\n",
    "covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space_arr = np.array(state_space)\n",
    "\n",
    "import functools\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def dynamic_solution(test_sets, results):\n",
    "    # array-ify\n",
    "    if not isinstance(results,tuple):\n",
    "        results = [results]\n",
    "    if len(test_sets) > 0 and not isinstance(test_sets[0],tuple):\n",
    "        test_sets = [test_sets]\n",
    "    test_sets_arr = np.array(test_sets)\n",
    "    test_sets_arr = test_sets_arr.reshape((test_sets_arr.size//N,N))\n",
    "    results_arr = np.array(results)\n",
    "    results_arr = results_arr.reshape((results_arr.size))\n",
    "    # compute the valid states\n",
    "    test_results = np.any(state_space_arr[:,:,np.newaxis] * test_sets_arr.T[np.newaxis,:,:], axis=1)\n",
    "    consistent_state = np.all(test_results == results_arr, axis=1)\n",
    "    reduced_state_space = state_space_arr[consistent_state]\n",
    "    if reduced_state_space.shape[0] == 1:\n",
    "        return 0, tuple()\n",
    "    if reduced_state_space.shape[0] == 0:\n",
    "        return -1, tuple()\n",
    "    # iterate over tests\n",
    "    known_values = np.logical_or(reduced_state_space.all(axis=0), np.logical_not(reduced_state_space).all(axis=0))\n",
    "    test_sets_set = set(test_sets)\n",
    "    min_expected_depth = np.inf\n",
    "    optimal_test_set = tuple([0])*N\n",
    "    for test_set in state_space:\n",
    "        test_set_arr = np.array(test_set)\n",
    "        # check if not already tested, or is looking at known values\n",
    "        if test_set not in test_sets_set and not np.any(test_set_arr * known_values):\n",
    "            # check if already covered by previous tests\n",
    "            covered_tests = np.logical_not(np.any(test_sets_arr * np.logical_not(test_set_arr), axis=1))\n",
    "            covered_tests = test_sets_arr[covered_tests]\n",
    "            covering = np.any(covered_tests, axis=0)\n",
    "            if np.any(covering != test_set_arr):\n",
    "                expected_depth = 0\n",
    "                # Compute probability of positive result\n",
    "                P_1 = 0.5\n",
    "                # Loop over possible results\n",
    "                print(reduced_state_space * np.array(test_set))\n",
    "                for result in [0,1]:\n",
    "                    # Create the sorted tuples for hashing\n",
    "                    new_test_sets = list(test_sets) + [test_set]\n",
    "                    new_results = list(results) + [result]\n",
    "                    new_sorted = sorted(zip(new_test_sets,new_results))\n",
    "                    new_test_sets = tuple([test[0] for test in new_sorted])\n",
    "                    new_results = tuple([test[1] for test in new_sorted])\n",
    "                    print(new_test_sets)\n",
    "                    print(new_results)\n",
    "                    # Perform the loop\n",
    "                    temp_expected_depth, _ = dynamic_solution(new_test_sets, new_results)\n",
    "                    expected_depth += (1+temp_expected_depth) * (P_1*result + (1-P_1)*(1-result))\n",
    "                # Update if this test set is more optimal\n",
    "                if expected_depth < min_expected_depth:\n",
    "                    min_expected_depth = expected_depth\n",
    "                    optimal_test_set = test_set\n",
    "    return min_expected_depth, optimal_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_solution(((0,1)), (0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f47ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_solution((), ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa19164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e479136",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://en.wikipedia.org/wiki/Decision_theory\n",
    "- https://numpy.org/doc/stable/reference/generated/numpy.logical_not.html\n",
    "- https://en.wikipedia.org/wiki/Hamming_space\n",
    "- https://en.wikipedia.org/wiki/Bernoulli_trial\n",
    "- https://en.wikipedia.org/wiki/Huffman_coding\n",
    "- https://math.stackexchange.com/questions/2299145/why-does-the-average-number-of-questions-bits-needed-for-storage-in-shannons-en\n",
    "- https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\n",
    "- https://en.wikipedia.org/wiki/Mutual_information\n",
    "- https://en.wikipedia.org/wiki/Conditional_probability\n",
    "- https://en.wikipedia.org/wiki/Shannon%27s_source_coding_theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb1d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
